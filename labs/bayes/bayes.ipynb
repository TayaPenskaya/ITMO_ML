{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm, tnrange\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_file(filename):\n",
    "    legit = 0\n",
    "    if \"legit\" in filename:\n",
    "        legit = 1\n",
    "    \n",
    "    with open(filename, \"r\") as file:\n",
    "        subject_words = file.readline()[9:-1].split()\n",
    "        file.readline()\n",
    "        message_words = file.readline()[:-1].split()\n",
    "        \n",
    "    return list(map(int, subject_words)), list(map(int, message_words)), legit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams_from_lists(subject_words, message_words, n):\n",
    "    subject_ngrams = [tuple(subject_words[j:j+n]) for j in range(len(subject_words)-n+1)]\n",
    "    message_ngrams = [tuple(message_words[j:j+n]) for j in range(len(message_words)-n+1)]\n",
    "    \n",
    "    if not subject_ngrams:\n",
    "        return message_ngrams\n",
    "    \n",
    "    return subject_ngrams + message_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_from_ngrams(letter, ndict):\n",
    "    vec = np.zeros(len(ndict))\n",
    "    \n",
    "    for ngram in letter:\n",
    "        vec[ndict[ngram]] = 1\n",
    "    \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prepared_data_from_dir(n, data_dirname='messages/'):\n",
    "    X = []\n",
    "    y = []\n",
    "    X_ngrams = []\n",
    "    all_ngrams = []\n",
    "\n",
    "    ngram_dict = {}\n",
    "\n",
    "    for dirname in os.listdir(data_dirname):\n",
    "        filenames = os.listdir(data_dirname + dirname)\n",
    "        full_filenames = [data_dirname + dirname + '/' + filename for filename in filenames]\n",
    "    \n",
    "        part_x = []\n",
    "        part_y = []\n",
    "        for name in full_filenames:\n",
    "            subject_words, message_words, legit = get_data_from_file(name)\n",
    "            cur_ngrams = get_ngrams_from_lists(subject_words, message_words, n)\n",
    "            part_x.append(cur_ngrams)\n",
    "            part_y.append(legit)\n",
    "            all_ngrams += cur_ngrams\n",
    "    \n",
    "        X_ngrams.append(part_x)\n",
    "        y.append(part_y)\n",
    "        \n",
    "    all_ngrams = list(set(all_ngrams))\n",
    "    \n",
    "    for i in range(len(all_ngrams)):\n",
    "        ngram_dict[all_ngrams[i]] = i\n",
    "    \n",
    "    for part in X_ngrams:\n",
    "        vpart = []\n",
    "        for letter in part:\n",
    "            vec = get_vector_from_ngrams(letter, ngram_dict)\n",
    "            vpart.append(vec)\n",
    "        X.append(vpart)\n",
    "        \n",
    "    return X, y, ngram_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes_a_priori_proba(labels):\n",
    "    legit = np.count_nonzero(labels)\n",
    "    return legit/len(labels), (len(labels)-legit)/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_laplas_proba(wcount, all_count, alpha):\n",
    "    return (wcount + alpha)/(all_count + alpha*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_words_cond_proba(X, y, ndict, alpha):\n",
    "    ndata = len(X)\n",
    "    \n",
    "    legit = X[y==1]\n",
    "    spam = X[y==0]\n",
    "    \n",
    "    vlegit = np.zeros(len(ndict))\n",
    "    vspam = np.zeros(len(ndict))\n",
    "    \n",
    "    for ngram in ndict:\n",
    "        flegit = list(filter(lambda x: x[ndict[ngram]], legit))\n",
    "        fspam = list(filter(lambda x: x[ndict[ngram]], spam))\n",
    "        vlegit[ndict[ngram]] = get_laplas_proba(len(flegit), len(legit), alpha)\n",
    "        vspam[ndict[ngram]] = get_laplas_proba(len(fspam), len(spam), alpha)\n",
    "    \n",
    "    return vlegit, vspam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_letter_proba(vletter, apri, vproba, lambda_):\n",
    "    lproba = [vproba[i] if vletter[i] else 1-vproba[i] for i in range(len(vletter))]\n",
    "    sum_cond_proba = sum(list(map(log, lproba)))\n",
    "    \n",
    "    return log(lambda_ * apri) + sum_cond_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_letter_class(vletter, apri_legit, apri_spam, vlegit, vspam, lambda_legit, lambda_spam):\n",
    "    legit_proba = get_letter_proba(vletter, apri_legit, vlegit, lambda_legit)\n",
    "    spam_proba = get_letter_proba(vletter, apri_spam, vspam, lambda_spam)\n",
    "    \n",
    "    if (legit_proba > spam_proba):\n",
    "        return 1\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation and finding hyper-params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_and_legit_neg(y_actual, y_pred):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for (a, p) in zip(y_actual, y_pred):\n",
    "        if a == p:\n",
    "            if p == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "        else:\n",
    "            if p == 1:\n",
    "                fp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "                \n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn) \n",
    "    \n",
    "    return accuracy, fn, tp/(tp+fn), fp/(fp+tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data_and_dict(n):\n",
    "    X, y, ndict = get_prepared_data_from_dir(n)\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        cur_train_x = np.delete(X, i, 0)\n",
    "        cur_train_y = np.delete(y, i, 0)\n",
    "        cur_test_x = X[:][i]\n",
    "        cur_test_y = y[:][i]\n",
    "        train_x.append(np.concatenate(cur_train_x))\n",
    "        train_y.append(np.concatenate(cur_train_y))\n",
    "        test_x.append(cur_test_x)\n",
    "        test_y.append(cur_test_y)\n",
    "        \n",
    "    return train_x, train_y, test_x, test_y, ndict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [1, 2, 3]\n",
    "alphas = [0.0001, 0.001, 0.1]\n",
    "lambda_legit = 1\n",
    "lambda_spam = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clf with finding best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4eb08e7ed84a46a5e5cca49a7651a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='clfprogress'), FloatProgress(value=0.0, max=90.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9669724770642203 6\n",
      "0.9623853211009175 7\n",
      "0.9559633027522935 8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-17b0d68f6fa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mvlegit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvspam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_words_cond_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mapri_legit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapri_spam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_classes_a_priori_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mtest_pred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_letter_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapri_legit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapri_spam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvlegit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvspam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_legit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_spam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mln\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy_and_legit_neg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pred_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-17b0d68f6fa9>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mvlegit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvspam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_words_cond_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mapri_legit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapri_spam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_classes_a_priori_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mtest_pred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_letter_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapri_legit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapri_spam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvlegit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvspam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_legit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_spam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mln\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy_and_legit_neg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pred_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-0c3939aba504>\u001b[0m in \u001b[0;36mget_letter_class\u001b[0;34m(vletter, apri_legit, apri_spam, vlegit, vspam, lambda_legit, lambda_spam)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_letter_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvletter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapri_legit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapri_spam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvlegit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvspam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_legit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_spam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlegit_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_letter_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvletter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapri_legit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvlegit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_legit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mspam_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_letter_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvletter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapri_spam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvspam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_spam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlegit_proba\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mspam_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-aa229794c77f>\u001b[0m in \u001b[0;36mget_letter_proba\u001b[0;34m(vletter, apri, vproba, lambda_)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_letter_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvletter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvproba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvproba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvletter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mvproba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvletter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msum_cond_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlproba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mapri\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msum_cond_proba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-aa229794c77f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_letter_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvletter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvproba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvproba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvletter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mvproba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvletter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msum_cond_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlproba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mapri\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msum_cond_proba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "min_ln = 100000\n",
    "best_params = []\n",
    "best_roc = []\n",
    "legit_neg = []\n",
    "accs = []\n",
    "\n",
    "with tqdm(total=len(ns)*len(alphas)*10, desc=\"clfprogress\", leave=False) as trp:\n",
    "    for n in ns:\n",
    "        for alpha in alphas:\n",
    "            accs = []\n",
    "            legit_neg = []\n",
    "            tprs = []\n",
    "            fprs = []\n",
    "            train_x, train_y, test_x, test_y, ndict = get_train_test_data_and_dict(n)\n",
    "            for i in range(10):\n",
    "                vlegit, vspam = get_all_words_cond_proba(train_x[i], train_y[i], ndict, alpha)\n",
    "                apri_legit, apri_spam = get_classes_a_priori_proba(train_y[i])\n",
    "                test_pred_y = list(map(lambda x: get_letter_class(x, apri_legit, apri_spam, vlegit, vspam, lambda_legit, lambda_spam), test_x[i]))\n",
    "                accuracy, ln, tpr, fpr = get_accuracy_and_legit_neg(test_y[i], test_pred_y)\n",
    "                accs.append(accuracy)\n",
    "                legit_neg.append(ln)\n",
    "                tprs.append(tpr)\n",
    "                fprs.append(fpr)\n",
    "\n",
    "                trp.update(1)\n",
    "            average_acc = sum(accs)/len(accs)\n",
    "            sum_ln = sum(legit_neg)\n",
    "            print(str(average_acc) + \" \" + str(sum_ln))\n",
    "            if sum_ln < min_ln or sum_ln == min_ln and average_acc > best_acc:\n",
    "                best_acc = average_acc\n",
    "                min_l = sum_ln\n",
    "                best_params = [n, alpha, lambda_legit]\n",
    "                best_roc = [tprs, fprs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"ROC Curve\")\n",
    "plt.plot(best_roc[0], best_roc[1])\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_accs = []\n",
    "\n",
    "lambdas_legits = [1, 100, 1000, 10000]\n",
    "for ll in lambdas_legit:\n",
    "    accs = []\n",
    "    train_x, train_y, test_x, test_y, ndict = get_train_test_data_and_dict(best_params[0])\n",
    "    for i in range(10):\n",
    "        vlegit, vspam = get_all_words_cond_proba(train_x[i], train_y[i], ndict, best_params[1])\n",
    "        apri_legit, apri_spam = get_classes_a_priori_proba(train_y[i])\n",
    "        test_pred_y = list(map(lambda x: get_letter_class(x, apri_legit, apri_spam, vlegit, vspam, ll, lambda_spam), test_x[i]))\n",
    "        accuracy, ln, tpr, fpr = get_accuracy_and_legit_neg(test_y[i], test_pred_y)\n",
    "        accs.append(accuracy)\n",
    "    average_accs.append(sum(accs)/len(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lambdas_legit, average_accs)\n",
    "plt.xlabel(\"lambda legit\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
